{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AILAND: A Repository for Crafting Enterprise-Grade AI Applications","text":""},{"location":"#about","title":"About","text":"<p>This repository is dedicated to helping individuals and teams learn how to create enterprise-grade AI applications. It covers best practices in AI engineering, scalable AI application development, and strategies for building robust, production-ready AI solutions for the enterprise. Whether you are looking to craft AI-intensive applications that scale or seeking guidance on enterprise AI development, this project provides practical resources and examples to accelerate your journey.</p>"},{"location":"#repository-as-tutorial","title":"Repository as Tutorial","text":"<p>This repository is structured as a comprehensive tutorial, guiding you through the process of building enterprise-grade AI applications step-by-step. It includes code examples, best practices, and architectural patterns that are essential for developing scalable and maintainable AI solutions. You can go through chapter by chapter or explore specific topics of interest.</p>"},{"location":"chapter-01/02-secure-auth-azure-openai/","title":"Secure Authentication for Azure OpenAI Services: Beyond API Keys","text":"<p>Your API keys are like the master password to your digital kingdom \u2013 convenient for demos, catastrophic for production.</p> <p>Picture this: It's 3 AM, and you're getting alerts about unexpected charges on your Azure OpenAI service. Someone has gotten hold of your API key and is running their cryptocurrency mining experiment using your GPT-4 credits. Sound far-fetched? It happens more often than you'd think.</p> <p>In this deep dive, we'll explore why API keys should never see the light of production environments and how to implement bulletproof authentication for your Azure OpenAI.</p>"},{"location":"chapter-01/02-secure-auth-azure-openai/#why-api-keys-are-not-meant-for-enterprise-production","title":"Why API Keys are not Meant for Enterprise Production","text":"<p>Before we dive into solutions, let's understand the magnitude of the problem. API keys are essentially long-lived passwords with unlimited power:</p>"},{"location":"chapter-01/02-secure-auth-azure-openai/#potential-pitfalls","title":"Potential Pitfalls","text":"<ul> <li>No expiration date: That key you created 18 months ago? Still works perfectly</li> <li>Unlimited scope: One key, unlimited access to your entire Azure OpenAI resource</li> <li>Rotation nightmare: Changing keys means updating dozens of services simultaneously</li> <li>Storage sins: Keys end up in Git repos, Slack messages, and production logs</li> <li>Audit blindness: Who used the key? When? For what? Good luck figuring that out</li> </ul>"},{"location":"chapter-01/02-secure-auth-azure-openai/#real-cost-of-compromise","title":"Real Cost of Compromise","text":"<p>A leaked API key doesn't just mean unauthorized access \u2013 it means: - Financial drain: Attackers using your expensive AI models for their projects - Rate limit exhaustion: Your legitimate applications failing due to quota limits - Data exposure: Potential access to your conversation history and sensitive prompts - Compliance violations: Audit failures when you can't track usage patterns</p>"},{"location":"chapter-01/02-secure-auth-azure-openai/#so-whats-the-alternative","title":"So What\u2019s the Alternative?","text":"<p>The good news: Azure provides robust authentication mechanisms that are secure, manageable, and enterprise-ready. Here are few alternatives which we are going to explore in detail:</p> <ol> <li>Azure AD Token Authentication: Short-lived tokens scoped to specific resources</li> <li>Certificate-Based Authentication: Strong, production-grade security using X.509 certificates, good for cross cloud scenarios</li> <li>Default Azure Credential: Intelligent, multi-source credential resolution for various environments, good for application deployed in Azure with RBAC (Role-Based Access Control)</li> </ol> <p>You can not get Azure AD Token directly rather you need to use custom or default token provider to get the token, which is short lived and can be scoped to specific resources. So no 1 is not really an alternative, but you will have to use method 2 or 3 to get the token. Apart from these you can also use Managed Identity, which is a special case of Default Azure Credential.</p> <p>Full implementation of the solution can be found as packaged application library called <code>ailand</code> can be found in my github repo here.</p> <p>But Before we jump into the solution forst lets discuss another important aspect of secure authentication, which is environment variable management.</p>"},{"location":"chapter-01/02-secure-auth-azure-openai/#environment-variable-management-the-pydantic-advantage","title":"Environment Variable Management: The Pydantic Advantage","text":"<p>One of the biggest challenges in secure authentication is managing configuration without hardcoding sensitive values. So far I have a good experience with Pydantic settings management. </p>"},{"location":"chapter-01/02-secure-auth-azure-openai/#the-settings-architecture","title":"The Settings Architecture","text":"<p>Our settings system for <code>ailand</code> follows a clean hierarchy:</p> <pre><code>utils/settings/\n\u251c\u2500\u2500 base.py     # Abstract base settings with common functionality\n\u2514\u2500\u2500 core.py     # Concrete implementations for different auth scenarios\n</code></pre>"},{"location":"chapter-01/02-secure-auth-azure-openai/#base-settings-foundation-basepy","title":"Base Settings Foundation (<code>base.py</code>)","text":"<pre><code>from pathlib import Path\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\nfrom loguru import logger\n\n\nDEFAULT_ENV_PATH = Path(\".envs\")\nDEFAULT_ENV_FILE_CANDIDATES = [\n    DEFAULT_ENV_PATH.joinpath(\"local.env\"),\n    DEFAULT_ENV_PATH.joinpath(\"dev.env\"),\n]\n\n\ndef find_env_file_if_exists() -&gt; Path | None:\n        \"\"\"\n        Check for the existence of environment files in the default locations.\n        Returns the first found env file path or None if none exist.\n        \"\"\"\n        ... # Check the Implementation in GitHub repository\n        return None\n\n\nclass ABCBaseSettings(BaseSettings):\n    model_config = SettingsConfigDict(\n        env_file=find_env_file_if_exists(),\n        env_file_encoding=\"utf-8\",\n        extra=\"ignore\",\n        case_sensitive=False,\n    )\n\n    @classmethod\n    def from_env_file(cls, env_path: str | Path) -&gt; \"ABCBaseSettings\":\n        \"\"\"\n        Load settings from a specific environment file.\n        Raises FileNotFoundError if the file does not exist.\n        Args:\n            env_path: Path to the .env file to load settings from.\n        \"\"\"\n        env_path = Path(env_path)\n        if not env_path.exists():\n            raise FileNotFoundError(f\"Env file {env_path} does not exist.\")\n\n        class CustomSettings(cls):  # dynamically override model_config\n            model_config = SettingsConfigDict(\n                env_file=env_path,\n                env_file_encoding=\"utf-8\",\n                extra=\"ignore\",\n                case_sensitive=False,\n            )\n\n        return CustomSettings()\n</code></pre> <p>Using this base class, we can create specialized settings for different authentication methods but also we will be able to initialize settings from different environment files (<code>from_env_file</code>) or system environment variables which is fantastic for local development and prototyping in environment like Jupyter notebooks.</p>"},{"location":"chapter-01/02-secure-auth-azure-openai/#production-ready-settings-corepy","title":"Production-Ready Settings (<code>core.py</code>)","text":"<pre><code># core.py\n\nclass AOAISettings(ABCBaseSettings):\n    # Basic connection settings\n    OPENAI_API_BASE: str\n    OPENAI_API_BASE_SN: str  # Switzerland region endpoint\n\n\nclass AOAICerteSettings(AOAISettings):\n    # Certificate-based authentication\n    TENANT_ID: str\n    CLIENT_ID: str\n    RESOURCE: str\n    PUBLIC_CERT_KEY: str\n    PRIVATE_CERT_KEY: str\n\n    @property\n    def certificate_string(self) -&gt; bytes:\n        \"\"\"Combine certificates for Azure authentication\"\"\"\n        return self.PRIVATE_CERT_KEY.encode() + b\"\\n\" + self.PUBLIC_CERT_KEY.encode()\n\n# ... More settings classes like AOAIKeySettings for API key based auth\n</code></pre> <p>Now we have a separate settings class for certificate based authentication, we can also create another class for API key based authentication if needed.</p>"},{"location":"chapter-01/02-secure-auth-azure-openai/#why-this-approach-rocks","title":"Why This Approach Rocks","text":"<ol> <li>Type Safety: Pydantic validates your configuration at startup</li> <li>Environment Flexibility: Seamlessly switch between <code>.env</code> files and environment variables</li> <li>Post-Processing: Automatic URL normalization and certificate handling</li> <li>Fallback Strategy: Graceful degradation from local to dev to production settings</li> </ol>"},{"location":"chapter-01/02-secure-auth-azure-openai/#the-wrapper-client-azureopenaichatclient","title":"The Wrapper Client: <code>AzureOpenAIChatClient</code>","text":"<p>Lets discuss the client implementation for Azure OpenAI service, which is implemented in <code>src/ailand/core/clients/openai/chat.py</code>. This client encapsulates all the authentication logic and provides a simple interface for making chat completions, tool calling, and structured output parsing.</p> <pre><code>aoai_endpoint_settings = AOAIEndpointSettings()\naoai_key_settings = AOAIKeySettings()\n\n# \u26a0\ufe0f Development and testing ONLY\nclient = AzureOpenAIChatClient(\n    model=ChatModelSelection.GPT4_1_MINI,\n    api_version=APIVersion.DEFAULT,\n    endpoint=aoai_endpoint_settings.OPENAI_API_BASE_DEFAULT,\n    api_key=aoai_key_settings.OPENAI_API_BASE_DEFAULT\n)\n</code></pre> <p>When to use: Development, testing, quick prototypes When to avoid: Production, any environment where security matters</p>"},{"location":"chapter-01/02-secure-auth-azure-openai/#2-azure-ad-token-the-temporary-hero","title":"2. Azure AD Token: The Temporary Hero","text":"<pre><code># \ud83d\udd50 Short-lived token (typically 1 hour)\nfrom azure.identity import DefaultAzureCredential\n\ncredential = DefaultAzureCredential()\ntoken = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n\nclient = AzureOpenAIChatClient(\n    model=ChatModelSelection.GPT4_1_MINI,\n    api_version=APIVersion.DEFAULT,\n    endpoint=aoai_endpoint_settings.OPENAI_API_BASE_DEFAULT,\n    azure_ad_token=token.token\n)\n</code></pre> <p>Advantages:  - Automatic expiration (limited blast radius) - Integrates with Azure AD policies - Can be scoped to specific resources</p> <p>Use case: Service-to-service communication where you manage token lifecycle</p> <p>Complexity: - Requires token management (refreshing tokens)</p>"},{"location":"chapter-01/02-secure-auth-azure-openai/#3-certificate-based-authentication-the-production-champion","title":"3. Certificate-Based Authentication: The Production Champion","text":"<p>This is where our architecture really shines. The certificate-based approach leverages our settings system for maximum security:</p> <pre><code># \ud83d\udd10 Production-grade security\nsettings = AOAICerteSettings()\n\nclient = AzureOpenAIChatClient(\n    ... # Other parameters\n    aoai_settings=settings  # Client automatically uses certificate auth\n)\n</code></pre> <p>Behind the scenes, our client (<code>src/ailand/utils/core/clients/openai/chat.py</code>) uses the sophisticated authentication resolver:</p> <pre><code>def _resolve_authentication(self, api_key, azure_ad_token, aoai_settings):\n    # Certificate authentication (highest priority for settings-based auth)\n    if aoai_settings:\n        try:\n            return {\"azure_ad_token_provider\": get_cert_token_provider(aoai_settings)}\n        except Exception as e:\n            logger.warning(f\"Certificate auth failed: {e}\")\n\n    # Fallback to DefaultAzureCredential\n    try:\n        token_provider = get_bearer_token_provider(\n            DefaultAzureCredential(), \n            DEFAULT_COGNITIVE_SERVICE_ENDPOINT\n        )\n        return {\"azure_ad_token_provider\": token_provider}\n    except Exception as e:\n        raise ValueError(f\"No valid authentication method available: {e}\")\n</code></pre>"},{"location":"chapter-01/02-secure-auth-azure-openai/#4-default-azure-credential-the-intelligent-fallback","title":"4. Default Azure Credential: The Intelligent Fallback","text":"<pre><code>client = AzureOpenAIChatClient(\n    model=...,\n    api_version=...,\n    endpoint=...,\n    # No explicit auth - DefaultAzureCredential takes over\n)\n</code></pre> <p>This method intelligently tries multiple authentication sources: 1. Environment variables (for containerized applications) 2. Managed Identity (when running in Azure) 3. Visual Studio Code credentials (for developers) 4. Azure CLI credentials (for local development)</p>"},{"location":"chapter-01/02-secure-auth-azure-openai/#environment-configuration-the-security-foundation","title":"Environment Configuration: The Security Foundation","text":""},{"location":"chapter-01/02-secure-auth-azure-openai/#development-environment-setup","title":"Development Environment Setup","text":"<p>Create <code>.envs/local.env</code> for local development:</p> <pre><code># Basic connection\nOPENAI_API_BASE_DEFAULT=https://your-resource.openai.azure.com\nOPENAI_API_BASE_ALT=https://your-alt-resource.openai.azure.com\n\n# Certificate-based auth (development certificates)\nTENANT_ID=... # Your Azure AD tenant ID\nCLIENT_ID=... # Your Azure AD app client ID\nRESOURCE=https://cognitiveservices.azure.com/.default\n\n# Certificates (properly escaped)\nPUBLIC_CERT_KEY=... # Read if from a PEM file or environment variable\nPRIVATE_CERT_KEY=... # Read if from a PEM file or environment variable\n\n# Logging control\nLOG_LEVEL=DEBUG\n</code></pre> <p>So when app is deployed in Azure or AWS the App will expect that the environment variables are set in the environment itself from a devops pipeline, which is a best practice. When running the app locally it will look for <code>.envs/local.env</code> or <code>.envs/dev.env</code> file. You can check the full implementation of the wrapper client in my github repo here.</p>"}]}